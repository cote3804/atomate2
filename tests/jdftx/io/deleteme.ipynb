{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\n",
      "A module that was compiled using NumPy 1.x cannot be run in\n",
      "NumPy 2.1.0 as it may crash. To support both 1.x and 2.x\n",
      "versions of NumPy, modules must be compiled with NumPy 2.0.\n",
      "Some module may need to rebuild instead e.g. with 'pybind11>=2.12'.\n",
      "\n",
      "If you are a user of the module, the easiest solution will be to\n",
      "downgrade to 'numpy<2' or try to upgrade the affected module.\n",
      "We expect that some modules will need time to support NumPy 2.\n",
      "\n",
      "Traceback (most recent call last):  File \"<frozen runpy>\", line 198, in _run_module_as_main\n",
      "  File \"<frozen runpy>\", line 88, in _run_code\n",
      "  File \"/Users/richb/anaconda3/envs/dev3_atomate2/lib/python3.12/site-packages/ipykernel_launcher.py\", line 18, in <module>\n",
      "    app.launch_new_instance()\n",
      "  File \"/Users/richb/anaconda3/envs/dev3_atomate2/lib/python3.12/site-packages/traitlets/config/application.py\", line 1075, in launch_instance\n",
      "    app.start()\n",
      "  File \"/Users/richb/anaconda3/envs/dev3_atomate2/lib/python3.12/site-packages/ipykernel/kernelapp.py\", line 739, in start\n",
      "    self.io_loop.start()\n",
      "  File \"/Users/richb/anaconda3/envs/dev3_atomate2/lib/python3.12/site-packages/tornado/platform/asyncio.py\", line 205, in start\n",
      "    self.asyncio_loop.run_forever()\n",
      "  File \"/Users/richb/anaconda3/envs/dev3_atomate2/lib/python3.12/asyncio/base_events.py\", line 641, in run_forever\n",
      "    self._run_once()\n",
      "  File \"/Users/richb/anaconda3/envs/dev3_atomate2/lib/python3.12/asyncio/base_events.py\", line 1987, in _run_once\n",
      "    handle._run()\n",
      "  File \"/Users/richb/anaconda3/envs/dev3_atomate2/lib/python3.12/asyncio/events.py\", line 88, in _run\n",
      "    self._context.run(self._callback, *self._args)\n",
      "  File \"/Users/richb/anaconda3/envs/dev3_atomate2/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 545, in dispatch_queue\n",
      "    await self.process_one()\n",
      "  File \"/Users/richb/anaconda3/envs/dev3_atomate2/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 534, in process_one\n",
      "    await dispatch(*args)\n",
      "  File \"/Users/richb/anaconda3/envs/dev3_atomate2/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 437, in dispatch_shell\n",
      "    await result\n",
      "  File \"/Users/richb/anaconda3/envs/dev3_atomate2/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 362, in execute_request\n",
      "    await super().execute_request(stream, ident, parent)\n",
      "  File \"/Users/richb/anaconda3/envs/dev3_atomate2/lib/python3.12/site-packages/ipykernel/kernelbase.py\", line 778, in execute_request\n",
      "    reply_content = await reply_content\n",
      "  File \"/Users/richb/anaconda3/envs/dev3_atomate2/lib/python3.12/site-packages/ipykernel/ipkernel.py\", line 449, in do_execute\n",
      "    res = shell.run_cell(\n",
      "  File \"/Users/richb/anaconda3/envs/dev3_atomate2/lib/python3.12/site-packages/ipykernel/zmqshell.py\", line 549, in run_cell\n",
      "    return super().run_cell(*args, **kwargs)\n",
      "  File \"/Users/richb/anaconda3/envs/dev3_atomate2/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3075, in run_cell\n",
      "    result = self._run_cell(\n",
      "  File \"/Users/richb/anaconda3/envs/dev3_atomate2/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3130, in _run_cell\n",
      "    result = runner(coro)\n",
      "  File \"/Users/richb/anaconda3/envs/dev3_atomate2/lib/python3.12/site-packages/IPython/core/async_helpers.py\", line 128, in _pseudo_sync_runner\n",
      "    coro.send(None)\n",
      "  File \"/Users/richb/anaconda3/envs/dev3_atomate2/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3334, in run_cell_async\n",
      "    has_raised = await self.run_ast_nodes(code_ast.body, cell_name,\n",
      "  File \"/Users/richb/anaconda3/envs/dev3_atomate2/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3517, in run_ast_nodes\n",
      "    if await self.run_code(code, result, async_=asy):\n",
      "  File \"/Users/richb/anaconda3/envs/dev3_atomate2/lib/python3.12/site-packages/IPython/core/interactiveshell.py\", line 3577, in run_code\n",
      "    exec(code_obj, self.user_global_ns, self.user_ns)\n",
      "  File \"/var/folders/v3/dhcqls6s33s55hmm47b0wr500000gn/T/ipykernel_15158/2655105922.py\", line 2, in <module>\n",
      "    from atomate2.jdftx.io.JDFTXOutfile import JDFTXOutfile\n",
      "  File \"/Users/richb/vs/atomate2/src/atomate2/__init__.py\", line 6, in <module>\n",
      "    SETTINGS = Atomate2Settings()\n",
      "  File \"/Users/richb/anaconda3/envs/dev3_atomate2/lib/python3.12/site-packages/pydantic_settings/main.py\", line 144, in __init__\n",
      "    super().__init__(\n",
      "  File \"/Users/richb/anaconda3/envs/dev3_atomate2/lib/python3.12/site-packages/pydantic/main.py\", line 193, in __init__\n",
      "    self.__pydantic_validator__.validate_python(data, self_instance=self)\n",
      "  File \"/Users/richb/vs/atomate2/src/atomate2/settings.py\", line 256, in load_default_settings\n",
      "    from monty.serialization import loadfn\n",
      "  File \"/Users/richb/anaconda3/envs/dev3_atomate2/lib/python3.12/site-packages/monty/serialization.py\", line 18, in <module>\n",
      "    from monty.json import MontyDecoder, MontyEncoder\n",
      "  File \"/Users/richb/anaconda3/envs/dev3_atomate2/lib/python3.12/site-packages/monty/json.py\", line 56, in <module>\n",
      "    import torch\n",
      "  File \"/Users/richb/anaconda3/envs/dev3_atomate2/lib/python3.12/site-packages/torch/__init__.py\", line 1477, in <module>\n",
      "    from .functional import *  # noqa: F403\n",
      "  File \"/Users/richb/anaconda3/envs/dev3_atomate2/lib/python3.12/site-packages/torch/functional.py\", line 9, in <module>\n",
      "    import torch.nn.functional as F\n",
      "  File \"/Users/richb/anaconda3/envs/dev3_atomate2/lib/python3.12/site-packages/torch/nn/__init__.py\", line 1, in <module>\n",
      "    from .modules import *  # noqa: F403\n",
      "  File \"/Users/richb/anaconda3/envs/dev3_atomate2/lib/python3.12/site-packages/torch/nn/modules/__init__.py\", line 35, in <module>\n",
      "    from .transformer import TransformerEncoder, TransformerDecoder, \\\n",
      "  File \"/Users/richb/anaconda3/envs/dev3_atomate2/lib/python3.12/site-packages/torch/nn/modules/transformer.py\", line 20, in <module>\n",
      "    device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n",
      "/Users/richb/anaconda3/envs/dev3_atomate2/lib/python3.12/site-packages/torch/nn/modules/transformer.py:20: UserWarning: Failed to initialize NumPy: _ARRAY_API not found (Triggered internally at /Users/runner/work/pytorch/pytorch/pytorch/torch/csrc/utils/tensor_numpy.cpp:84.)\n",
      "  device: torch.device = torch.device(torch._C._get_default_device()),  # torch.device('cpu'),\n"
     ]
    }
   ],
   "source": [
    "from pathlib import Path\n",
    "from atomate2.jdftx.io.JDFTXOutfile import JDFTXOutfile\n",
    "from atomate2.jdftx.io.JDFTXInfile import JDFTXInfile\n",
    "from pytest import approx\n",
    "import pytest\n",
    "from pymatgen.util.typing import PathLike\n",
    "from pymatgen.core.units import Ha_to_eV\n",
    "import os\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "from functools import wraps\n",
    "import math\n",
    "from ase import Atom, Atoms\n",
    "from atomate2.jdftx.io.JMinSettings import JMinSettings, JMinSettingsElectronic, JMinSettingsFluid, JMinSettingsIonic, JMinSettingsLattice\n",
    "import numpy as np\n",
    "from dataclasses import dataclass, field\n",
    "import scipy.constants as const\n",
    "from atomate2.jdftx.io.data import atom_valence_electrons\n",
    "from atomate2.jdftx.io.JOutStructures import JOutStructures\n",
    "from pymatgen.core import Structure\n",
    "from pymatgen.core.trajectory import Trajectory\n",
    "from typing import List, Optional\n",
    "from pymatgen.core.units import Ha_to_eV, ang_to_bohr, bohr_to_ang\n",
    "\n",
    "\n",
    "class ClassPrintFormatter():\n",
    "    def __str__(self) -> str:\n",
    "        '''generic means of printing class to command line in readable format'''\n",
    "        return str(self.__class__) + '\\n' + '\\n'.join((str(item) + ' = ' + str(self.__dict__[item]) for item in sorted(self.__dict__)))\n",
    "\n",
    "\n",
    "def get_start_lines(text: list[str], start_key: Optional[str]=\"*************** JDFTx\", add_end: Optional[bool]=False) -> list[int]:\n",
    "    '''\n",
    "    Get the line numbers corresponding to the beginning of seperate JDFTx calculations\n",
    "    (in case of multiple calculations appending the same out file)\n",
    "\n",
    "    Args:\n",
    "        text: output of read_file for out file\n",
    "    '''\n",
    "    start_lines = []\n",
    "    for i, line in enumerate(text):\n",
    "        if start_key in line:\n",
    "            start_lines.append(i)\n",
    "    if add_end:\n",
    "        start_lines.append(i)\n",
    "    return start_lines\n",
    "\n",
    "def find_key_first(key_input, tempfile):\n",
    "    '''\n",
    "    Finds first instance of key in output file. \n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    key_input: str\n",
    "        key string to match\n",
    "    tempfile: List[str]\n",
    "        output from readlines() function in read_file method\n",
    "    '''\n",
    "    key_input = str(key_input)\n",
    "    line = None\n",
    "    for i in range(0,len(tempfile)):\n",
    "        if key_input in tempfile[i]:\n",
    "            line = i\n",
    "            break\n",
    "    return line\n",
    "\n",
    "\n",
    "def find_key(key_input, tempfile):\n",
    "    '''\n",
    "    Finds last instance of key in output file. \n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    key_input: str\n",
    "        key string to match\n",
    "    tempfile: List[str]\n",
    "        output from readlines() function in read_file method\n",
    "    '''\n",
    "    key_input = str(key_input)\n",
    "    line = None\n",
    "    lines = find_all_key(key_input, tempfile)\n",
    "    if len(lines):\n",
    "        line = lines[-1]\n",
    "    # line = None\n",
    "    # for i in range(0,len(tempfile)):\n",
    "    #     if key_input in tempfile[i]:\n",
    "    #         line = i\n",
    "    return line\n",
    "\n",
    "\n",
    "def find_first_range_key(key_input: str, tempfile: list[str], startline: int=0, endline: int=-1, skip_pound:bool = False) -> list[int]:\n",
    "    '''\n",
    "    Find all lines that exactly begin with key_input in a range of lines\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    key_input: str\n",
    "        key string to match\n",
    "    tempfile: List[str]\n",
    "        output from readlines() function in read_file method\n",
    "    startline: int\n",
    "        line to start searching from\n",
    "    endline: int\n",
    "        line to stop searching at\n",
    "    skip_pound: bool\n",
    "        whether to skip lines that begin with a pound sign\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    L: list[int]\n",
    "        list of line numbers where key_input occurs\n",
    "    \n",
    "    '''\n",
    "    key_input = str(key_input)\n",
    "    startlen = len(key_input)\n",
    "    L = []\n",
    "\n",
    "    if endline == -1:\n",
    "        endline = len(tempfile)\n",
    "    for i in range(startline,endline):\n",
    "        line = tempfile[i]\n",
    "        if skip_pound == True:\n",
    "            for j in range(10):  #repeat to make sure no really weird formatting\n",
    "                line = line.lstrip()\n",
    "                line = line.lstrip('#')\n",
    "        line = line[0:startlen]\n",
    "        if line == key_input:\n",
    "            L.append(i)\n",
    "    if not L:\n",
    "        L = [len(tempfile)]\n",
    "    return L\n",
    "\n",
    "def key_exists(key_input, tempfile):\n",
    "    line = find_key(key_input, tempfile)\n",
    "    if line == None:\n",
    "        return False\n",
    "    else:\n",
    "        return True\n",
    "\n",
    "def find_all_key(key_input, tempfile, startline = 0):\n",
    "    # Ben: I don't think this is deprecated by find_first_range_key, since this function\n",
    "    # doesn't require the key to be at the beginning of the line\n",
    "    #DEPRECATED: NEED TO REMOVE INSTANCES OF THIS FUNCTION AND SWITCH WITH find_first_range_key\n",
    "    #finds all lines where key occurs in in lines\n",
    "    L = []     #default\n",
    "    key_input = str(key_input)\n",
    "    for i in range(startline,len(tempfile)):\n",
    "        if key_input in tempfile[i]:\n",
    "            L.append(i)\n",
    "    return L\n",
    "\n",
    "@dataclass\n",
    "class JDFTXOutfileSlice(ClassPrintFormatter):\n",
    "    '''\n",
    "    A class to read and process a JDFTx out file\n",
    "\n",
    "    Attributes:\n",
    "        see JDFTx documentation for tag info and typing\n",
    "    '''\n",
    "\n",
    "    prefix: str = None\n",
    "\n",
    "    jstrucs: JOutStructures = None\n",
    "    jsettings_fluid: JMinSettingsFluid = None\n",
    "    jsettings_electronic: JMinSettingsElectronic = None\n",
    "    jsettings_lattice: JMinSettingsLattice = None\n",
    "    jsettings_ionic: JMinSettingsIonic = None\n",
    "\n",
    "    xc_func: str = None\n",
    "\n",
    "    lattice_initial: list[list[float]] = None\n",
    "    lattice_final: list[list[float]] = None\n",
    "    lattice: list[list[float]] = None\n",
    "    a: float = None\n",
    "    b: float = None\n",
    "    c: float = None\n",
    "\n",
    "    fftgrid: list[int] = None\n",
    "    geom_opt: bool = None\n",
    "    geom_opt_type: str = None\n",
    "\n",
    "    # grouping fields related to electronic parameters.\n",
    "    # Used by the get_electronic_output() method\n",
    "    _electronic_output = [ \n",
    "    \"EFermi\", \"Egap\", \"Emin\", \"Emax\", \"HOMO\",\n",
    "    \"LUMO\", \"HOMO_filling\", \"LUMO_filling\", \"is_metal\"\n",
    "    ]\n",
    "    EFermi: float = None\n",
    "    Egap: float = None\n",
    "    Emin: float = None\n",
    "    Emax: float = None\n",
    "    HOMO: float = None\n",
    "    LUMO: float = None\n",
    "    HOMO_filling: float = None\n",
    "    LUMO_filling: float = None\n",
    "    is_metal: bool = None\n",
    "\n",
    "    broadening_type: str = None\n",
    "    broadening: float = None\n",
    "    kgrid: list = None\n",
    "    truncation_type: str = None\n",
    "    truncation_radius: float = None\n",
    "    pwcut: float = None\n",
    "    rhocut: float = None\n",
    "\n",
    "    pp_type: str = None\n",
    "    total_electrons: float = None\n",
    "    semicore_electrons: int = None\n",
    "    valence_electrons: float = None\n",
    "    total_electrons_uncharged: int = None\n",
    "    semicore_electrons_uncharged: int = None\n",
    "    valence_electrons_uncharged: int = None\n",
    "    Nbands: int = None\n",
    "\n",
    "    atom_elements: list = None\n",
    "    atom_elements_int: list = None\n",
    "    atom_types: list = None\n",
    "    spintype: str = None\n",
    "    Nspin: int = None\n",
    "    Nat: int = None\n",
    "    atom_coords_initial: list[list[float]] = None\n",
    "    atom_coords_final: list[list[float]] = None\n",
    "    atom_coords: list[list[float]] = None\n",
    "\n",
    "    has_solvation: bool = False\n",
    "    fluid: str = None\n",
    "\n",
    "    # #@ Cooper added @#\n",
    "    # Ecomponents: dict = field(default_factory=dict)\n",
    "    # is_gc: bool = False # is it a grand canonical calculation\n",
    "    # trajectory_positions: list[list[list[float]]] = None\n",
    "    # trajectory_lattice: list[list[list[float]]] = None\n",
    "    # trajectory_forces: list[list[list[float]]] = None\n",
    "    # trajectory_ecomponents: list[dict] = None\n",
    "    # # is_converged: bool = None #TODO implement this\n",
    "\n",
    "    @property\n",
    "    def t_s(self) -> float:\n",
    "        '''\n",
    "        Returns the total time in seconds for the calculation\n",
    "\n",
    "        Returns:\n",
    "        -------\n",
    "        t_s: float\n",
    "            The total time in seconds for the calculation\n",
    "        '''\n",
    "        t_s = None\n",
    "        if self.jstrucs:\n",
    "            t_s = self.jstrucs.t_s\n",
    "        return t_s\n",
    "    \n",
    "\n",
    "    @property\n",
    "    def is_converged(self) -> bool:\n",
    "        '''\n",
    "        Returns True if the electronic and geometric optimization have converged\n",
    "        (or only the former if a single-point calculation)\n",
    "        '''\n",
    "        converged = self.jstrucs.elec_converged\n",
    "        if self.geom_opt:\n",
    "            converged = converged and self.jstrucs.geom_converged\n",
    "        return converged\n",
    "\n",
    "\n",
    "    @property\n",
    "    def trajectory(self) -> Trajectory:\n",
    "        '''\n",
    "        Returns a pymatgen trajectory object\n",
    "        '''\n",
    "        constant_lattice = self.jsettings_lattice.nIterations == 0\n",
    "        traj = Trajectory.from_structures(\n",
    "            structures=self.jstrucs,\n",
    "            constant_lattice=constant_lattice\n",
    "        )\n",
    "        return traj\n",
    "\n",
    "    \n",
    "    @property\n",
    "    def electronic_output(self) -> dict:\n",
    "        '''\n",
    "        Return a dictionary with all relevant electronic information.\n",
    "        Returns values corresponding to these keys in _electronic_output\n",
    "        field.\n",
    "        '''\n",
    "        dct = {}\n",
    "        for field in self.__dataclass_fields__:\n",
    "            if field in self._electronic_output:\n",
    "                value = getattr(self, field)\n",
    "                dct[field] = value\n",
    "        return dct\n",
    "    \n",
    "    \n",
    "    @property\n",
    "    def structure(self) -> Structure:\n",
    "        structure = self.jstrucs[-1]\n",
    "        return structure\n",
    "    \n",
    "    \n",
    "    @classmethod\n",
    "    def from_out_slice(cls, text: list[str]):\n",
    "        '''\n",
    "        Read slice of out file into a JDFTXOutfileSlice instance\n",
    "\n",
    "        Parameters:\n",
    "        ----------\n",
    "        text: list[str]\n",
    "            file to read\n",
    "        '''\n",
    "        instance = cls()\n",
    "\n",
    "        instance._set_min_settings(text)\n",
    "        instance._set_geomopt_vars(text)\n",
    "        instance._set_jstrucs(text)\n",
    "        instance.prefix = instance._get_prefix(text)\n",
    "        spintype, Nspin = instance._get_spinvars(text)\n",
    "        instance.xc_func =instance._get_xc_func(text)\n",
    "        instance.spintype = spintype\n",
    "        instance.Nspin = Nspin\n",
    "        broadening_type, broadening = instance._get_broadeningvars(text)\n",
    "        instance.broadening_type = broadening_type\n",
    "        instance.broadening = broadening\n",
    "        instance.kgrid = instance._get_kgrid(text)\n",
    "        truncation_type, truncation_radius = instance._get_truncationvars(text)\n",
    "        instance.truncation_type = truncation_type\n",
    "        instance.truncation_radius = truncation_radius\n",
    "        instance.pwcut = instance._get_pw_cutoff(text)\n",
    "        instance.rhocut = instance._get_rho_cutoff(text)\n",
    "        instance.fftgrid = instance._get_fftgrid(text)\n",
    "        instance._set_eigvars(text)\n",
    "        instance._set_orb_fillings()\n",
    "        instance.is_metal = instance._determine_is_metal()\n",
    "        instance._set_fluid(text)\n",
    "        instance._set_total_electrons(text)\n",
    "        instance._set_Nbands(text)\n",
    "        instance._set_atom_vars(text)\n",
    "        instance._set_pseudo_vars(text)\n",
    "        instance._set_lattice_vars(text)\n",
    "        instance.has_solvation = instance.check_solvation()\n",
    "\n",
    "        \n",
    "\n",
    "        #@ Cooper added @#\n",
    "        instance.is_gc = key_exists('target-mu', text)\n",
    "        instance._set_ecomponents(text)\n",
    "        # instance._build_trajectory(templines)\n",
    "\n",
    "        return instance\n",
    "    \n",
    "\n",
    "    def _get_xc_func(self, text: list[str]) -> str:\n",
    "        '''\n",
    "        Get the exchange-correlation functional used in the calculation\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        text: list[str]\n",
    "            output of read_file for out file\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        xc_func: str\n",
    "            exchange-correlation functional used\n",
    "        '''\n",
    "        line = find_key('elec-ex-corr', text)\n",
    "        xc_func = text[line].strip().split()[-1].strip()\n",
    "        return xc_func\n",
    "        \n",
    "    \n",
    "\n",
    "    def _get_prefix(self, text: list[str]) -> str:\n",
    "        '''\n",
    "        Get output prefix from the out file\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "            text: list[str]\n",
    "                output of read_file for out file\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "            prefix: str\n",
    "                prefix of dump files for JDFTx calculation\n",
    "        '''\n",
    "        prefix = None\n",
    "        line = find_key('dump-name', text)\n",
    "        dumpname = text[line].split()[1]\n",
    "        if \".\" in dumpname:\n",
    "            prefix = dumpname.split('.')[0]\n",
    "        return prefix\n",
    "    \n",
    "    def _get_spinvars(self, text: list[str]) -> tuple[str, int]:\n",
    "        '''\n",
    "        Set spintype and Nspin from out file text for instance\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        text: list[str]\n",
    "            output of read_file for out file\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        spintype: str\n",
    "            type of spin in calculation\n",
    "        Nspin: int\n",
    "            number of spin types in calculation\n",
    "        '''\n",
    "        line = find_key('spintype ', text)\n",
    "        spintype = text[line].split()[1]\n",
    "        if spintype == 'no-spin':\n",
    "            spintype = None\n",
    "            Nspin = 1\n",
    "        elif spintype == 'z-spin':\n",
    "            Nspin = 2\n",
    "        else:\n",
    "            raise NotImplementedError('have not considered this spin yet')\n",
    "        return spintype, Nspin\n",
    "    \n",
    "    def _get_broadeningvars(self, text:list[str]) -> tuple[str, float]:\n",
    "        '''\n",
    "        Get broadening type and value from out file text\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        text: list[str]\n",
    "            output of read_file for out file\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        broadening_type: str\n",
    "            type of electronic smearing\n",
    "        broadening: float\n",
    "            parameter for electronic smearing\n",
    "        '''\n",
    "        line = find_key('elec-smearing ', text)\n",
    "        if not line is None:\n",
    "            broadening_type = text[line].split()[1]\n",
    "            broadening = float(text[line].split()[2])\n",
    "        else:\n",
    "            broadening_type = None\n",
    "            broadening = 0\n",
    "        return broadening_type, broadening\n",
    "    \n",
    "    def _get_truncationvars(self, text:list[str]) -> tuple[str, float]:\n",
    "        '''\n",
    "        Get truncation type and value from out file text\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        text: list[str]\n",
    "            output of read_file for out file\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        truncation_type: str\n",
    "            type of coulomb truncation\n",
    "        truncation_radius: float | None\n",
    "            radius of truncation (if truncation_type is spherical)\n",
    "        '''\n",
    "        maptypes = {'Periodic': None, 'Slab': 'slab', 'Cylindrical': 'wire', 'Wire': 'wire',\n",
    "                    'Spherical': 'spherical', 'Isolated': 'box'}\n",
    "        line = find_key('coulomb-interaction', text)\n",
    "        truncation_type = None\n",
    "        truncation_radius = None\n",
    "        if not line is None:\n",
    "            truncation_type = text[line].split()[1]\n",
    "            truncation_type = maptypes[truncation_type]\n",
    "            direc = None\n",
    "            if len(text[line].split()) == 3:\n",
    "                direc = text[line].split()[2]\n",
    "            if truncation_type == 'slab' and direc != '001':\n",
    "                raise ValueError('BGW slab Coulomb truncation must be along z!')\n",
    "            if truncation_type == 'wire' and direc != '001':\n",
    "                raise ValueError('BGW wire Coulomb truncation must be periodic in z!')\n",
    "            if truncation_type == 'error':\n",
    "                raise ValueError('Problem with this truncation!')\n",
    "            if truncation_type == 'spherical':\n",
    "                line = find_key('Initialized spherical truncation of radius', text)\n",
    "                truncation_radius = float(text[line].split()[5]) / ang_to_bohr\n",
    "        return truncation_type, truncation_radius\n",
    "    \n",
    "    \n",
    "    def _get_pw_cutoff(self, text:list[str]) -> float:\n",
    "        '''\n",
    "        Get the electron cutoff from the out file text\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        text: list[str]\n",
    "            output of read_file for out file\n",
    "        '''\n",
    "        line = find_key('elec-cutoff ', text)\n",
    "        pwcut = float(text[line].split()[1]) * Ha_to_eV\n",
    "        return pwcut\n",
    "    \n",
    "    \n",
    "    def _get_rho_cutoff(self, text:list[str]) -> float:\n",
    "        '''\n",
    "        Get the electron cutoff from the out file text\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        text: list[str]\n",
    "            output of read_file for out file\n",
    "        '''\n",
    "        line = find_key('elec-cutoff ', text)\n",
    "        lsplit = text[line].split()\n",
    "        if len(lsplit) == 3:\n",
    "            rhocut = float(lsplit[2]) * Ha_to_eV\n",
    "        else:\n",
    "            pwcut = self.pwcut\n",
    "            if self.pwcut is None:\n",
    "                pwcut = self._get_pw_cutoff(text)\n",
    "            rhocut = float(pwcut * 4)\n",
    "        return rhocut\n",
    "    \n",
    "\n",
    "    def _get_fftgrid(self, text:list[str]) -> list[int]:\n",
    "        '''\n",
    "        Get the FFT grid from the out file text\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        text: list[str]\n",
    "            output of read_file for out file\n",
    "        '''\n",
    "        line = find_key_first('Chosen fftbox size', text)\n",
    "        fftgrid = [int(x) for x in text[line].split()[6:9]]\n",
    "        return fftgrid\n",
    "    \n",
    "\n",
    "    def _get_kgrid(self, text:list[str]) -> list[int]:\n",
    "        '''\n",
    "        Get the kpoint grid from the out file text\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "            text: list[str]\n",
    "                output of read_file for out file\n",
    "        '''\n",
    "        line = find_key('kpoint-folding ', text)\n",
    "        kgrid = [int(x) for x in text[line].split()[1:4]]\n",
    "        return kgrid\n",
    "    \n",
    "    \n",
    "    def _get_eigstats_varsdict(self, text:list[str], prefix:str | None) -> dict[str, float]:\n",
    "        '''\n",
    "        Get the eigenvalue statistics from the out file text\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        text: list[str]\n",
    "            output of read_file for out file\n",
    "        prefix: str\n",
    "            prefix for the eigStats section in the out file\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        varsdict: dict[str, float]\n",
    "            dictionary of eigenvalue statistics\n",
    "        '''\n",
    "        varsdict = {}\n",
    "        _prefix = \"\"\n",
    "        if not prefix is None:\n",
    "            _prefix = f\"{prefix}.\"\n",
    "        line = find_key(f'Dumping \\'{_prefix}eigStats\\' ...', text)\n",
    "        if line is None:\n",
    "            raise ValueError('Must run DFT job with \"dump End EigStats\" to get summary gap information!')\n",
    "        varsdict[\"Emin\"] = float(text[line+1].split()[1]) * Ha_to_eV\n",
    "        varsdict[\"HOMO\"] = float(text[line+2].split()[1]) * Ha_to_eV\n",
    "        varsdict[\"EFermi\"] = float(text[line+3].split()[2]) * Ha_to_eV\n",
    "        varsdict[\"LUMO\"] = float(text[line+4].split()[1]) * Ha_to_eV\n",
    "        varsdict[\"Emax\"] = float(text[line+5].split()[1]) * Ha_to_eV\n",
    "        varsdict[\"Egap\"] = float(text[line+6].split()[2]) * Ha_to_eV\n",
    "        return varsdict\n",
    "    \n",
    "    \n",
    "    def _set_eigvars(self, text:list[str]) -> None:\n",
    "        '''\n",
    "        Set the eigenvalue statistics variables\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        text: list[str]\n",
    "            output of read_file for out file\n",
    "        '''\n",
    "        eigstats = self._get_eigstats_varsdict(text, self.prefix)\n",
    "        self.Emin = eigstats[\"Emin\"]\n",
    "        self.HOMO = eigstats[\"HOMO\"]\n",
    "        self.EFermi = eigstats[\"EFermi\"]\n",
    "        self.LUMO = eigstats[\"LUMO\"]\n",
    "        self.Emax = eigstats[\"Emax\"]\n",
    "        self.Egap = eigstats[\"Egap\"]\n",
    "    \n",
    "\n",
    "    def _get_pp_type(self, text:list[str]) -> str:\n",
    "        '''\n",
    "        Get the pseudopotential type used in calculation\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        text: list[str]\n",
    "            output of read_file for out file\n",
    "\n",
    "        Returns\n",
    "        ----------\n",
    "        pptype: str\n",
    "            Pseudopotential library used\n",
    "        '''\n",
    "        skey = \"Reading pseudopotential file\"\n",
    "        line = find_key(skey, text)\n",
    "        ppfile_example = text[line].split(skey)[1].split(\":\")[0].strip(\"'\")\n",
    "        pptype = None\n",
    "        readable = [\"GBRV\", \"SG15\"]\n",
    "        for _pptype in readable:\n",
    "            if _pptype in ppfile_example:\n",
    "                if not pptype is None:\n",
    "                    if ppfile_example.index(pptype) < ppfile_example.index(_pptype):\n",
    "                        pptype = _pptype\n",
    "                    else:\n",
    "                        pass\n",
    "                else:\n",
    "                    pptype = _pptype\n",
    "        if pptype is None:\n",
    "            raise ValueError(f\"Could not determine pseudopotential type from file name {ppfile_example}\")\n",
    "        return pptype\n",
    "    \n",
    "    \n",
    "    def _set_pseudo_vars(self, text:list[str]) -> None:\n",
    "        '''\n",
    "        Set the pseudopotential variables   \n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        text: list[str]\n",
    "            output of read_file for out file\n",
    "        '''\n",
    "        self.pp_type = self._get_pp_type(text)\n",
    "        if self.pp_type == \"SG15\":\n",
    "            self._set_pseudo_vars_SG15(text)\n",
    "        elif self.pp_type == \"GBRV\":\n",
    "            self._set_pseudo_vars_GBRV(text)\n",
    "    \n",
    "    \n",
    "    def _set_pseudo_vars_SG15(self, text:list[str]) -> None:\n",
    "        '''\n",
    "        Set the pseudopotential variables for SG15 pseudopotentials\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        text: list[str]\n",
    "            output of read_file for out file\n",
    "        '''\n",
    "        startline = find_key('---------- Setting up pseudopotentials ----------', text)\n",
    "        endline = find_first_range_key('Initialized ', text, startline = startline)[0]\n",
    "        lines = find_all_key('valence electrons', text)\n",
    "        lines = [x for x in lines if x < endline and x > startline]\n",
    "        atom_total_elec = [int(float(text[x].split()[0])) for x in lines]\n",
    "        total_elec_dict = dict(zip(self.atom_types, atom_total_elec))\n",
    "        element_total_electrons = np.array([total_elec_dict[x] for x in self.atom_elements])\n",
    "        element_valence_electrons = np.array([atom_valence_electrons[x] for x in self.atom_elements])\n",
    "        element_semicore_electrons = element_total_electrons - element_valence_electrons\n",
    "        self.total_electrons_uncharged = np.sum(element_total_electrons)\n",
    "        self.valence_electrons_uncharged = np.sum(element_valence_electrons)\n",
    "        self.semicore_electrons_uncharged = np.sum(element_semicore_electrons)\n",
    "        self.semicore_electrons = self.semicore_electrons_uncharged\n",
    "        self.valence_electrons = self.total_electrons - self.semicore_electrons  #accounts for if system is charged\n",
    "\n",
    "\n",
    "    def _set_pseudo_vars_GBRV(self, text:list[str]) -> None:\n",
    "        ''' TODO: implement this method\n",
    "        '''\n",
    "        self.total_electrons_uncharged = None\n",
    "        self.valence_electrons_uncharged = None\n",
    "        self.semicore_electrons_uncharged = None\n",
    "        self.semicore_electrons = None\n",
    "        self.valence_electrons = None\n",
    "\n",
    "\n",
    "    def _collect_settings_lines(self, text:list[str], start_flag:str) -> list[int]:\n",
    "        '''\n",
    "        Collect the lines of settings from the out file text\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        text: list[str]\n",
    "            output of read_file for out file\n",
    "        start_flag: str\n",
    "            key to start collecting settings lines\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        lines: list[int]\n",
    "            list of line numbers where settings occur\n",
    "        '''\n",
    "        started = False\n",
    "        lines = []\n",
    "        for i, line in enumerate(text):\n",
    "            if started:\n",
    "                if line.strip().split()[-1].strip() == \"\\\\\":\n",
    "                    lines.append(i)\n",
    "                else:\n",
    "                    started = False\n",
    "            elif start_flag in line:\n",
    "                started = True\n",
    "                #lines.append(i) # we DONT want to do this\n",
    "            elif len(lines):\n",
    "                break\n",
    "        return lines\n",
    "    \n",
    "\n",
    "    def _create_settings_dict(self, text:list[str], start_flag:str) -> dict:\n",
    "        '''\n",
    "        Create a dictionary of settings from the out file text\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        text: list[str]\n",
    "            output of read_file for out file\n",
    "        start_flag: str\n",
    "            key to start collecting settings lines\n",
    "\n",
    "        Returns\n",
    "        -------\n",
    "        settings_dict: dict\n",
    "            dictionary of settings\n",
    "        '''\n",
    "        lines = self._collect_settings_lines(text, start_flag)\n",
    "        settings_dict = {}\n",
    "        for line in lines:\n",
    "            line_text_list = text[line].strip().split()\n",
    "            key = line_text_list[0]\n",
    "            value = line_text_list[1]\n",
    "            settings_dict[key] = value\n",
    "        return settings_dict\n",
    "    \n",
    "    \n",
    "    def _get_settings_object(self, text:list[str], settings_class: JMinSettings) -> JMinSettings:\n",
    "        '''\n",
    "        Get the settings object from the out file text\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        text: list[str]\n",
    "            output of read_file for out file\n",
    "        settings_class: JMinSettings\n",
    "            settings class to create object from\n",
    "            \n",
    "        Returns\n",
    "        -------\n",
    "        settings_obj: JMinSettings\n",
    "            settings object\n",
    "        '''\n",
    "        settings_dict = self._create_settings_dict(text, settings_class.start_flag)\n",
    "        if len(settings_dict):\n",
    "            settings_obj = settings_class(**settings_dict)\n",
    "        else:\n",
    "            settings_obj = None\n",
    "        return settings_obj\n",
    "    \n",
    "\n",
    "    def _set_min_settings(self, text:list[str]) -> None:\n",
    "        '''\n",
    "        Set the settings objects from the out file text\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        text: list[str]\n",
    "            output of read_file for out file\n",
    "        '''\n",
    "        self.jsettings_fluid = self._get_settings_object(text, JMinSettingsFluid)\n",
    "        self.jsettings_electronic = self._get_settings_object(text, JMinSettingsElectronic)\n",
    "        self.jsettings_lattice = self._get_settings_object(text, JMinSettingsLattice)\n",
    "        self.jsettings_ionic = self._get_settings_object(text, JMinSettingsIonic)\n",
    "    \n",
    "\n",
    "    def _set_geomopt_vars(self, text:list[str]) -> None:\n",
    "        ''' \n",
    "        Set vars geom_opt and geom_opt_type for initializing self.jstrucs\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "            text: list[str]\n",
    "                output of read_file for out file\n",
    "        '''\n",
    "        if self.jsettings_ionic is None or self.jsettings_lattice is None:\n",
    "            self._set_min_settings(text)\n",
    "        #\n",
    "        if self.jsettings_ionic is None or self.jsettings_lattice is None:\n",
    "            raise ValueError(\"Unknown issue in setting settings objects\")\n",
    "        else:\n",
    "            if self.jsettings_lattice.nIterations > 0:\n",
    "                self.geom_opt = True\n",
    "                self.geom_opt_type = \"lattice\"\n",
    "            elif self.jsettings_ionic.nIterations > 0:\n",
    "                self.geom_opt = True\n",
    "                self.geom_opt_type = \"ionic\"\n",
    "            else:\n",
    "                self.geom_opt = False\n",
    "                self.geom_opt_type = \"single point\"\n",
    "\n",
    "\n",
    "    def _set_jstrucs(self, text:list[str]) -> None:\n",
    "        '''\n",
    "        Set the JStructures object from the out file text\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "            text: list[str]\n",
    "                output of read_file for out file\n",
    "        '''\n",
    "        self.jstrucs = JOutStructures.from_out_slice(text, iter_type=self.geom_opt_type)\n",
    "\n",
    "\n",
    "    def _set_orb_fillings(self) -> None:\n",
    "        '''\n",
    "        Calculate and set HOMO and LUMO fillings\n",
    "        '''\n",
    "        if self.broadening_type is not None:\n",
    "            self.HOMO_filling = (2 / self.Nspin) * self.calculate_filling(self.broadening_type, self.broadening, self.HOMO, self.EFermi)\n",
    "            self.LUMO_filling = (2 / self.Nspin) * self.calculate_filling(self.broadening_type, self.broadening, self.LUMO, self.EFermi)\n",
    "        else:\n",
    "            self.HOMO_filling = (2 / self.Nspin)\n",
    "            self.LUMO_filling = 0\n",
    "\n",
    "\n",
    "    def _set_fluid(self, text: list[str]) -> None: # Is this redundant to the fluid settings?\n",
    "        '''\n",
    "        Set the fluid class variable\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        text: list[str]\n",
    "            output of read_file for out file\n",
    "        '''\n",
    "        line = find_first_range_key('fluid ', text)\n",
    "        self.fluid = text[line[0]].split()[1]\n",
    "        if self.fluid == 'None':\n",
    "            self.fluid = None\n",
    "\n",
    "\n",
    "    def _set_total_electrons(self, text:str) -> None:\n",
    "        '''\n",
    "        Set the total_Electrons class variable\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        text: list[str]\n",
    "            output of read_file for out file\n",
    "        '''\n",
    "        total_electrons = self.jstrucs[-1].elecMinData[-1].nElectrons\n",
    "        self.total_electrons = total_electrons\n",
    "        # lines = find_all_key('nElectrons', text)\n",
    "        # if len(lines) > 1:\n",
    "        #     idx = 4\n",
    "        # else:\n",
    "        #     idx = 1  #nElectrons was not printed in scf iterations then\n",
    "        # self.total_electrons = float(text[lines[-1]].split()[idx])\n",
    "    \n",
    "\n",
    "    def _set_Nbands(self, text: list[str]) -> None:\n",
    "        '''\n",
    "        Set the Nbands class variable\n",
    "\n",
    "        Parameters\n",
    "        ----------\n",
    "        text: list[str]\n",
    "            output of read_file for out file\n",
    "        '''\n",
    "        lines = find_all_key('elec-n-bands', text)\n",
    "        line = lines[0]\n",
    "        nbands = int(text[line].strip().split()[-1].strip())\n",
    "        self.Nbands = nbands\n",
    "    \n",
    "\n",
    "    def _set_atom_vars(self, text: list[str]) -> None:\n",
    "        '''\n",
    "        Set the atom variables\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        text: list[str]\n",
    "            output of read_file for out file'''\n",
    "        startline = find_key('Input parsed successfully', text)\n",
    "        endline = find_key('---------- Initializing the Grid ----------', text)\n",
    "        lines = find_first_range_key('ion ', text, startline = startline, endline = endline)\n",
    "        atom_elements = [text[x].split()[1] for x in lines]\n",
    "        self.Nat = len(atom_elements)\n",
    "        atom_coords = [text[x].split()[2:5] for x in lines]\n",
    "        self.atom_coords_initial = np.array(atom_coords, dtype = float)\n",
    "        atom_types = []\n",
    "        for x in atom_elements:\n",
    "            if not x in atom_types:\n",
    "                atom_types.append(x)\n",
    "        self.atom_elements = atom_elements\n",
    "        mapping_dict = dict(zip(atom_types, range(1, len(atom_types) + 1)))\n",
    "        self.atom_elements_int = [mapping_dict[x] for x in self.atom_elements]\n",
    "        self.atom_types = atom_types\n",
    "        line = find_key('# Ionic positions in', text) + 1\n",
    "        coords = np.array([text[i].split()[2:5] for i in range(line, line + self.Nat)], dtype = float)\n",
    "        self.atom_coords_final = coords\n",
    "        self.atom_coords = self.atom_coords_final.copy()\n",
    "    \n",
    "\n",
    "    def _set_lattice_vars(self, text: list[str]) -> None:\n",
    "        '''\n",
    "        Set the lattice variables\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        text: list[str]\n",
    "            output of read_file for out file\n",
    "        '''\n",
    "        self.lattice_initial = self.jstrucs[0].lattice.matrix\n",
    "        self.lattice_final = self.jstrucs[-1].lattice.matrix\n",
    "        self.lattice = self.lattice_final.copy()\n",
    "        # This block was throwing errors\n",
    "        # lines = find_all_key('R =', text)\n",
    "        # line = lines[0]\n",
    "        # lattice_initial = np.array([x.split()[1:4] for x in text[(line + 1):(line + 4)]], dtype = float).T / ang_to_bohr\n",
    "        # self.lattice_initial = lattice_initial.copy()\n",
    "        # templines = find_all_key('LatticeMinimize', text)\n",
    "        # if len(templines) > 0:\n",
    "        #     line = templines[-1]\n",
    "        #     lattice_final = np.array([x.split()[1:4] for x in text[(line + 1):(line + 4)]], dtype = float).T / ang_to_bohr\n",
    "        #     self.lattice_final = lattice_final.copy()\n",
    "        #     self.lattice = lattice_final.copy()\n",
    "        # else:\n",
    "        #     self.lattice = lattice_initial.copy()\n",
    "        self.a, self.b, self.c = np.sum(self.lattice**2, axis = 1)**0.5\n",
    "\n",
    "\n",
    "    def _set_ecomponents(self, text: list[str]) -> None:\n",
    "        '''\n",
    "        Set the energy components dictionary\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        text: list[str]\n",
    "            output of read_file for out file\n",
    "        '''\n",
    "        line = find_key(\"# Energy components:\", text)\n",
    "        self.Ecomponents = self._read_ecomponents(line, text)\n",
    "\n",
    "\n",
    "    def calculate_filling(self, broadening_type, broadening, eig, EFermi):\n",
    "        #most broadening implementations do not have the denominator factor of 2, but JDFTx does currently\n",
    "        #   remove if use this for other code outfile reading\n",
    "        x = (eig - EFermi) / (2.0 * broadening)\n",
    "        if broadening_type == 'Fermi':\n",
    "            filling = 0.5 * (1 - np.tanh(x))\n",
    "        elif broadening_type == 'Gauss':\n",
    "            filling = 0.5 * (1 - math.erf(x))\n",
    "        elif broadening_type == 'MP1':\n",
    "            filling = 0.5 * (1 - math.erf(x)) - x * np.exp(-1 * x**2) / (2 * np.pi**0.5)\n",
    "        elif broadening_type == 'Cold':\n",
    "            filling = 0.5* (1 - math.erf(x + 0.5**0.5)) + np.exp(-1 * (x + 0.5**0.5)**2) / (2 * np.pi)**0.5\n",
    "        else:\n",
    "            raise NotImplementedError('Have not added other broadening types')\n",
    "\n",
    "        return filling\n",
    "    \n",
    "\n",
    "    def _determine_is_metal(self) -> bool:\n",
    "        '''\n",
    "        Determine if the system is a metal based on the fillings of HOMO and LUMO\n",
    "\n",
    "        Returns\n",
    "        --------\n",
    "        is_metal: bool\n",
    "            True if system is metallic\n",
    "        '''\n",
    "        TOL_PARTIAL = 0.01\n",
    "        is_metal = True\n",
    "        if self.HOMO_filling / (2 / self.Nspin) > (1 - TOL_PARTIAL) and self.LUMO_filling / (2 / self.Nspin) < TOL_PARTIAL:\n",
    "            is_metal = False\n",
    "        return is_metal\n",
    "    \n",
    "\n",
    "    def check_solvation(self) -> bool:\n",
    "        '''\n",
    "        Check if calculation used implicit solvation\n",
    "        \n",
    "        Returns\n",
    "        --------\n",
    "        has_solvation: bool\n",
    "            True if calculation used implicit solvation\n",
    "        '''\n",
    "        has_solvation = self.fluid is not None\n",
    "        return has_solvation\n",
    "    \n",
    "\n",
    "    def write():\n",
    "        #don't need a write method since will never do that\n",
    "        return NotImplementedError('There is no need to write a JDFTx out file')\n",
    "    \n",
    "\n",
    "    def _build_trajectory(self, text):\n",
    "        '''\n",
    "        Builds the trajectory lists and sets the instance attributes.\n",
    "        \n",
    "        '''\n",
    "        # Needs to handle LatticeMinimize and IonicMinimize steps in one run\n",
    "        # can do this by checking if lattice vectors block is present and if\n",
    "        # so adding it to the lists. If it isn't present, copy the last \n",
    "        # lattice from the list.\n",
    "        # initialize lattice list with starting lattice and remove it\n",
    "        # from the list after iterating through all the optimization steps\n",
    "        trajectory_positions = []\n",
    "        trajectory_lattice = [self.lattice_initial]\n",
    "        trajectory_forces = []\n",
    "        trajectory_ecomponents = []\n",
    "\n",
    "        ion_lines = find_first_range_key('# Ionic positions in', text)\n",
    "        force_lines = find_first_range_key('# Forces in', text)\n",
    "        ecomp_lines = find_first_range_key('# Energy components:', text)\n",
    "        # print(ion_lines, force_lines, ecomp_lines)\n",
    "        for iline, ion_line, force_line, ecomp_line in enumerate(zip(ion_lines, force_lines, ecomp_lines)):\n",
    "            coords = np.array([text[i].split()[2:5] for i in range(ion_line + 1, ion_line + self.Nat + 1)], dtype = float)\n",
    "            forces = np.array([text[i].split()[2:5] for i in range(force_line + 1, force_line + self.Nat + 1)], dtype = float)\n",
    "            ecomp = self._read_ecomponents(ecomp_line, text)\n",
    "            lattice_lines = find_first_range_key('# Lattice vectors:', text, startline=ion_line, endline=ion_lines[iline-1])\n",
    "            if len(lattice_lines) == 0: # if no lattice lines found, append last lattice\n",
    "                trajectory_lattice.append(trajectory_lattice[-1])\n",
    "            else:\n",
    "                line = lattice_lines[0]\n",
    "                trajectory_lattice.append(np.array([x.split()[1:4] for x in text[(line + 1):(line + 4)]], dtype = float).T / ang_to_bohr)\n",
    "            trajectory_positions.append(coords)\n",
    "            trajectory_forces.append(forces)\n",
    "            trajectory_ecomponents.append(ecomp)\n",
    "        trajectory_lattice = trajectory_lattice[1:] # remove starting lattice\n",
    "\n",
    "        self.trajectory_positions = trajectory_positions\n",
    "        self.trajectory_lattice = trajectory_lattice\n",
    "        self.trajectory_forces = trajectory_forces\n",
    "        self.trajectory_ecomponents = trajectory_ecomponents\n",
    "    \n",
    "\n",
    "    def _read_ecomponents(self, line:int, text:str) -> dict:\n",
    "        '''\n",
    "        Read the energy components from the out file text\n",
    "        \n",
    "        Parameters\n",
    "        ----------\n",
    "        line: int\n",
    "            line number where energy components are found\n",
    "        text: list[str]\n",
    "            output of read_file for out file\n",
    "        \n",
    "        Returns\n",
    "        -------\n",
    "        Ecomponents: dict\n",
    "            dictionary of energy components\n",
    "        '''\n",
    "        Ecomponents = {}\n",
    "        if self.is_gc == True:\n",
    "            final_E_type = \"G\"\n",
    "        else:\n",
    "            final_E_type = \"F\"\n",
    "        for tmp_line in text[line+1:]:\n",
    "            chars = tmp_line.strip().split()\n",
    "            if tmp_line.startswith(\"--\"):\n",
    "                continue\n",
    "            E_type = chars[0]\n",
    "            Energy = float(chars[-1]) * Ha_to_eV\n",
    "            Ecomponents.update({E_type:Energy})\n",
    "            if E_type == final_E_type:\n",
    "                return Ecomponents\n",
    "        \n",
    "\n",
    "    \n",
    "\n",
    "    def to_dict(self) -> dict:\n",
    "        # convert dataclass to dictionary representation\n",
    "        dct = {}\n",
    "        for field in self.__dataclass_fields__:\n",
    "            value = getattr(self, field)\n",
    "            dct[field] = value\n",
    "        return dct\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "import math\n",
    "import os\n",
    "from dataclasses import dataclass\n",
    "from functools import wraps\n",
    "from dataclasses import dataclass\n",
    "from typing import List, Optional\n",
    "\n",
    "\n",
    "class ClassPrintFormatter():\n",
    "\n",
    "    def __str__(self) -> str:\n",
    "        \"\"\"Generic means of printing class to command line in readable format\"\"\"\n",
    "        return (\n",
    "            str(self.__class__)\n",
    "            + \"\\n\"\n",
    "            + \"\\n\".join(\n",
    "                str(item) + \" = \" + str(self.__dict__[item])\n",
    "                for item in sorted(self.__dict__)\n",
    "            )\n",
    "        )\n",
    "\n",
    "\n",
    "def check_file_exists(func):\n",
    "    \"\"\"Check if file exists (and continue normally) or raise an exception if it does not\"\"\"\n",
    "\n",
    "    @wraps(func)\n",
    "    def wrapper(filename):\n",
    "        if not os.path.isfile(filename):\n",
    "            raise OSError(\"'\" + filename + \"' file doesn't exist!\")\n",
    "        return func(filename)\n",
    "\n",
    "    return wrapper\n",
    "\n",
    "\n",
    "@check_file_exists\n",
    "def read_file(file_name: str) -> list[str]:\n",
    "    '''\n",
    "    Read file into a list of str\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    filename: Path or str\n",
    "        name of file to read\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    text: list[str]\n",
    "        list of strings from file\n",
    "    '''\n",
    "    with open(file_name, 'r') as f:\n",
    "        text = f.readlines()\n",
    "    return text\n",
    "\n",
    "\n",
    "def get_start_lines(text: list[str], start_key: Optional[str]=\"*************** JDFTx\", add_end: Optional[bool]=False) -> list[int]:\n",
    "    '''\n",
    "    Get the line numbers corresponding to the beginning of seperate JDFTx calculations\n",
    "    (in case of multiple calculations appending the same out file)\n",
    "\n",
    "    Args:\n",
    "        text: output of read_file for out file\n",
    "    '''\n",
    "    start_lines = []\n",
    "    for i, line in enumerate(text):\n",
    "        if start_key in line:\n",
    "            start_lines.append(i)\n",
    "    if add_end:\n",
    "        start_lines.append(i)\n",
    "    return start_lines\n",
    "\n",
    "def read_outfile_slices(file_name: str) -> list[list[str]]:\n",
    "    '''\n",
    "    Read slice of out file into a list of str\n",
    "\n",
    "    Parameters\n",
    "    ----------\n",
    "    filename: Path or str\n",
    "        name of file to read\n",
    "    out_slice_idx: int\n",
    "        index of slice to read from file\n",
    "\n",
    "    Returns\n",
    "    -------\n",
    "    texts: list[list[str]]\n",
    "        list of out file slices (individual calls of JDFTx)\n",
    "    '''\n",
    "    _text = read_file(file_name)\n",
    "    start_lines = get_start_lines(_text, add_end=True)\n",
    "    texts = []\n",
    "    for i in range(len(start_lines)-1):\n",
    "        text = _text[start_lines[i]:start_lines[i+1]]\n",
    "        texts.append(text)\n",
    "    return texts\n",
    "\n",
    "\n",
    "@dataclass\n",
    "class JDFTXOutfile(List[JDFTXOutfileSlice], ClassPrintFormatter):\n",
    "    '''\n",
    "    A class to read and process a JDFTx out file\n",
    "    '''\n",
    "\n",
    "    @classmethod\n",
    "    def from_file(cls, file_path: str):\n",
    "        texts = read_outfile_slices(file_path)\n",
    "        instance = cls()\n",
    "        for text in texts:\n",
    "            instance.append(JDFTXOutfileSlice.from_out_slice(text))\n",
    "        return instance\n",
    "\n",
    "    def __getattr__(self, name):\n",
    "        if len(self):\n",
    "            return getattr(self[-1], name)\n",
    "        else:\n",
    "            try:\n",
    "                return super().__getattr__(name)\n",
    "            except AttributeError:\n",
    "                if self:\n",
    "                    return getattr(self[-1], name)\n",
    "                raise AttributeError(f\"'JDFTXOutfile' object has no attribute '{name}'\")\n",
    "\n",
    "    def __setattr__(self, name, value):\n",
    "        # Do we want this? I don't imagine this class object should be modified\n",
    "        if name in self.__annotations__:\n",
    "            super().__setattr__(name, value)\n",
    "        elif self:\n",
    "            setattr(self[-1], name, value)\n",
    "        else:\n",
    "            raise AttributeError(f\"'JDFTXOutfile' object has no attribute '{name}'\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "single point\n",
      "None\n"
     ]
    }
   ],
   "source": [
    "test = JDFTXOutfile.from_file(Path(os.getcwd()) / \"example_files\" /  \"example_sp.out\")\n",
    "print(test[-1].jstrucs.iter_type)\n",
    "print(test[-1].t_s)\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [],
   "source": [
    "from atomate2.jdftx.io.JDFTXInfile_master_format import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "tag_ex = \"fluid-anion\"\n",
    "\n",
    "instance = JDFTXInfile()\n",
    "lines = [\"fluid-anion Cl- 0.5\",\n",
    "         \"lattice \\\\\",\n",
    "         \"1.0 0.0 0.0 \\\\\",\n",
    "         \"1.0 0.0 0.0 \\\\\",\n",
    "         \"1.0 0.0 0.0\",\n",
    "         \"latt-move-scale 0 0 0\",\n",
    "         \"ion Cl 0.0 0.0 0.0 1\",\n",
    "         \"ion-species GBRV_v1.5/$ID_pbe_v1.uspp\"]\n",
    "# lines = instance._gather_tags(lines)\n",
    "\n",
    "test = JDFTXInfile.from_str(\"\\n\".join(lines))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "dev_atomate2",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
